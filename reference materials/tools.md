## Data Acquisition
- experiments
- observational studies
- existing datasets
- SQL
- NoSQL
- "flat files" (ex: csv, xls, json, xlm, etc)
- webscraping
- simulation
- images


## Pre-processing
- consistent formatting (ex: upper/lower case, float/int, ...)
- regex
- quality assurance (outlier detection, erroneous data, fraud, ...)


## Feature Engineering
- Categorical -> dummy/indicator variable (ex: One-Hot-Encoding, Multi-label binarizer, ...)
- Impute missing data
- Rescale, remove skew (min-max rescaling, z-transform, robust transform, ...)
- Create new variables
- Clustering
  - k-Means
  - Gaussian Mixtures
- Dimensionality Reduction/Compression techniques
  - Principal Components
- Natural Language embeddings
  - n-grams
  - word-to-vec


## Cross-Validation
- k-Fold
- Leave-one-out
- Delete-d
- Bootstrap


## Supervised Learning
- k-Nearest Neighbors
- Support Vector Machines
- Artificial Neural Networks
- Naive Bayes
- Decision Trees
- Ensembles of supervised learners


## Model Performance
- classification accuracy
- confusion matrix
- sensitivity/recall, specificity precision, F_1, F_beta
- Receiver-Operator Curve (ROC) curve & Area Under the Curve (AUR)
- cost matrix
- over/under sampling for class imbalance problems



